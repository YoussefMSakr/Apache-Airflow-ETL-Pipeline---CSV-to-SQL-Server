# Apache Airflow ETL Pipeline - CSV to SQL Server

## ğŸ¯ Overview

A production-ready ETL pipeline built with Apache Airflow to automate the ingestion of CSV data into SQL Server. This pipeline processes thousands of records per run with comprehensive data validation, batch processing optimization, and idempotent design for reliable re-runs.

## âœ¨ Key Features

- âœ… **Automated Data Ingestion**: Scheduled extraction of CSV files
- âœ… **Data Validation**: Schema checks, NULL handling, and type validation
- âœ… **Batch Processing**: Optimized inserts (50 records per batch) for performance
- âœ… **Idempotent Design**: Safe re-runs with automated table creation
- âœ… **Error Handling**: Comprehensive logging and retry mechanisms
- âœ… **Scalable Architecture**: Handles up to 50 MB of data per execution

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV File  â”‚ â”€â”€â”€> â”‚   Airflow    â”‚ â”€â”€â”€> â”‚ SQL Server  â”‚
â”‚   Source    â”‚      â”‚   Pipeline   â”‚      â”‚  Database   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”œâ”€ Extract
                           â”œâ”€ Validate
                           â”œâ”€ Transform
                           â”œâ”€ Load (Batch)
                           â””â”€ Verify
```

## ğŸ› ï¸ Tech Stack

- **Orchestration:** Apache Airflow 2.x
- **Language:** Python 3.9+
- **Data Processing:** Pandas
- **Database:** SQL Server 2019+
- **Database Connector:** SQLAlchemy / pyodbc

## ğŸ“‚ Project Structure

```
airflow-csv-sql-etl/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ csv_to_sql_dag.py          # Main DAG definition
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py                  # CSV extraction logic
â”‚   â”œâ”€â”€ validate.py                 # Data validation functions
â”‚   â”œâ”€â”€ transform.py                # Data transformation
â”‚   â””â”€â”€ load.py                     # Batch loading to SQL Server
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                 # Configuration file
â”‚   â””â”€â”€ schema.json                 # Expected data schema
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py            # Unit tests
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ .gitignore
```

## ğŸš€ Getting Started

### Prerequisites

```bash
# Required software
- Python 3.9+
- Apache Airflow 2.0+
- SQL Server 2019+
- pip package manager
```

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/airflow-csv-sql-etl.git
cd airflow-csv-sql-etl
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Configure Airflow**
```bash
# Initialize Airflow database
airflow db init

# Create Airflow user
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com
```

4. **Configure SQL Server connection**
```bash
# Add connection in Airflow UI or via CLI
airflow connections add 'sql_server_conn' \
    --conn-type 'mssql' \
    --conn-host 'your-server' \
    --conn-schema 'your-database' \
    --conn-login 'your-username' \
    --conn-password 'your-password'
```

5. **Place DAG in Airflow**
```bash
cp dags/csv_to_sql_dag.py $AIRFLOW_HOME/dags/
```

## âš™ï¸ Configuration

Edit `config/config.yaml`:

```yaml
source:
  csv_path: "/path/to/csv/files"
  delimiter: ","
  encoding: "utf-8"

database:
  table_name: "target_table"
  batch_size: 50
  create_if_not_exists: true

validation:
  check_null: true
  check_duplicates: true
  required_columns:
    - id
    - name
    - value
```

## ğŸ“Š Pipeline Workflow

### 1. **Extract** ğŸ“¥
- Read CSV file from source location
- Handle file encoding and delimiters
- Log extraction metrics

### 2. **Validate** âœ…
- Schema validation against defined schema
- NULL value checks
- Data type verification
- Duplicate detection

### 3. **Transform** ğŸ”„
- Data type conversions
- Column renaming/mapping
- Date formatting
- NULL handling strategies

### 4. **Load** ğŸ“¤
- Batch processing (50 records/batch)
- Idempotent table creation
- Transaction management
- Performance optimization

### 5. **Verify** ğŸ”
- Record count validation
- Data quality checks
- Success/failure logging

## ğŸ“ˆ Performance Metrics

- **Processing Speed**: ~1,000 records/second
- **Batch Size**: 50 records per batch
- **Data Volume**: Up to 50 MB per run
- **Success Rate**: 99%+ with retry logic

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Test DAG validity
python dags/csv_to_sql_dag.py

# Airflow DAG test
airflow dags test csv_to_sql_etl 2024-01-01
```

## ğŸ“ Usage Example

```python
# Manual trigger via Python
from airflow.api.common.trigger_dag import trigger_dag

trigger_dag(
    dag_id='csv_to_sql_etl',
    conf={'csv_file': 'data_2024.csv'}
)
```

## ğŸ”„ DAG Schedule

- **Default Schedule**: Daily at 2:00 AM
- **Retries**: 3 attempts
- **Retry Delay**: 5 minutes
- **Timeout**: 30 minutes

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Connection to SQL Server fails
```bash
# Solution: Check SQL Server connection
airflow connections get sql_server_conn
```

**Issue**: DAG not appearing in UI
```bash
# Solution: Check DAG file syntax
python dags/csv_to_sql_dag.py
```

**Issue**: Memory error on large files
```bash
# Solution: Reduce batch size in config
batch_size: 25  # Instead of 50
```

## ğŸ“š Lessons Learned

- âœ… Batch processing significantly improves performance over row-by-row inserts
- âœ… Idempotent design is crucial for reliable re-runs
- âœ… Comprehensive logging saves debugging time
- âœ… Schema validation prevents downstream data quality issues


## ğŸ‘¤ Author

**Youssef Mohamed Sakr**
- Email: yousssseefssakr@gmail.com
- GitHub: https://github.com/YoussefMSakr
- LinkedIn: https://www.linkedin.com/in/youssef-mohamed-36bba4282

## ğŸ™ Acknowledgments

- Apache Airflow community for excellent documentation
- Stack Overflow for troubleshooting help
- IBM Data Engineering course for foundational knowledge

---

â­ If you found this project helpful, please give it a star!
